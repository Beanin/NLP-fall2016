{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/p3/lib/python3.4/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/root/p3/lib/python3.4/site-packages/sklearn/grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "from pandas import DataFrame\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>1) Скачаем датасет</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2017-05-17 19:52:10--  http://www.dt.fee.unicamp.br/~tiago/smsspamcollection/smsspamcollection.zip\n",
      "Resolving www.dt.fee.unicamp.br (www.dt.fee.unicamp.br)... 143.106.12.20\n",
      "Connecting to www.dt.fee.unicamp.br (www.dt.fee.unicamp.br)|143.106.12.20|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 210521 (206K) [application/zip]\n",
      "Saving to: ‘smsspamcollection.zip.1’\n",
      "\n",
      "100%[======================================>] 210 521     79,4KB/s   in 2,6s   \n",
      "\n",
      "2017-05-17 19:52:14 (79,4 KB/s) - ‘smsspamcollection.zip.1’ saved [210521/210521]\n",
      "\n",
      "Archive:  smsspamcollection.zip\n",
      "replace readme? [y]es, [n]o, [A]ll, [N]one, [r]ename: ^C\n"
     ]
    }
   ],
   "source": [
    "! wget http://www.dt.fee.unicamp.br/~tiago/smsspamcollection/smsspamcollection.zip\n",
    "! unzip smsspamcollection.zip\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>2,3) Считаем данные и подготовим списки признаков</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = open('SMSSpamCollection.txt')\n",
    "items = [line.strip('\\n').split('\\t')[::-1] for line in src.readlines()]\n",
    "texts = [it[0] for it in items]\n",
    "labels = [it[1] for it in items]\n",
    "for i, label in enumerate(labels):\n",
    "    labels[i] = 1 if label == 'spam' else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>4) получим признаки bag of words</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "features = vectorizer.fit_transform(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>5) Подготовим score_function</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_func(est, X, y):\n",
    "    cv = cross_val_score(est, X, y, cv=5, scoring='average_precision')\n",
    "    # print(cv)\n",
    "    return cv.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>проверим на LogisticRegression</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.973318472579\n"
     ]
    }
   ],
   "source": [
    "print(score_func(LogisticRegression(), features, labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Ответ в п.5 0.933348526858</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>6) Отклассифицируем данные сообщения классификатором, обученным на всей выборке</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = [\"FreeMsg: Txt: CALL to No:86888 & claim your reward of 3 hours talk time to use from your phone now! Subscribe6GB\",\n",
    "     \"FreeMsg: Txt: claim your reward of 3 hours talk time\",\n",
    "     \"Have you visited the last lecture on physics?\", \n",
    "     \"Have you visited the last lecture on physics? Just buy this book and you will have all materials! Only 99$\", \n",
    "     \"Only 99$\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "new_labels = LogisticRegression().fit(features, labels).predict(vectorizer.transform(x))\n",
    "print(new_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Ответ на п.6: \"1 1 0 0 0\"</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>7) Попробуем разные ngram_range</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ngram_ranges = [ (2, 2), (3, 3), (1, 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.95020180128\n",
      "0.898932803618\n",
      "0.975194915229\n"
     ]
    }
   ],
   "source": [
    "for ngram_range in ngram_ranges:\n",
    "    print(score_func(LogisticRegression(),\n",
    "                     CountVectorizer(ngram_range=ngram_range).fit_transform(texts),\n",
    "                     labels\n",
    "                     ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Ответ в п.7: \"0.82 0.73 0.93\"</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>8) То же самое для MultinomialNB()</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.963906947377\n",
      "0.866417933548\n",
      "0.979131556061\n"
     ]
    }
   ],
   "source": [
    "for ngram_range in ngram_ranges:\n",
    "    print(score_func(MultinomialNB(),\n",
    "                     CountVectorizer(ngram_range=ngram_range).fit_transform(texts),\n",
    "                     labels\n",
    "                     ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Ответ в п.8: \"0.65 0.39 0.89\"</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 9) Попробуем TfidfVectorizer + LogisticRegression</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.94377493097\n",
      "0.89870880652\n",
      "0.971449234172\n"
     ]
    }
   ],
   "source": [
    "for ngram_range in ngram_ranges:\n",
    "    print(score_func(LogisticRegression(),\n",
    "                     TfidfVectorizer(ngram_range=ngram_range).fit_transform(texts),\n",
    "                     labels\n",
    "                     ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> :( Из-за маленькой тренировочной выборки, многие стоп-слова получают большой вес</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 10) Попробуем улучшить score </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Заменим логистическую регрессию(один нейрон) на полносвязную нейросеть </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "best_score = 0\n",
    "best_layers = (1, )\n",
    "for i in range(100):\n",
    "    n_layers = random.randint(1, 4) # от 1 до 4 слоев\n",
    "    layers = []\n",
    "    for layer in range(n_layers):\n",
    "        layers.append(random.randint(1, 8)) # от 1 до 8 нейронов в слое\n",
    "    classifier = MLPClassifier(solver='lbfgs', hidden_layer_sizes=layers, random_state=1, activation='relu')\n",
    "    score = score_func(classifier, features, labels)\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_layers = layers\n",
    "        print(\"new best score %f\" % score)\n",
    "    if i % 10 == 0:\n",
    "        print(i, \"iterations passed...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.968315480645 [6]\n"
     ]
    }
   ],
   "source": [
    "print(best_score, best_layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> \"Затащила\" однослойная сеть из 6 нейронов </h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Попробуем понизить размерность <h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd = TruncatedSVD(1000)\n",
    "svd.fit(features)\n",
    "\n",
    "plt.figure(1, figsize=(4, 3))\n",
    "plt.clf()\n",
    "plt.axes([.2, .2, .7, .7])\n",
    "plt.plot(svd.explained_variance_, linewidth=2)\n",
    "plt.axis('tight')\n",
    "plt.xlabel('n_components')\n",
    "plt.ylabel('explained_variance_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N_COMP = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svd = TruncatedSVD(N_COMP)\n",
    "logistic = LogisticRegression(n_jobs=-1, class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(steps=[('svd', svd), ('logistic', logistic)])\n",
    "Cs = np.logspace(-2, 2, 20)\n",
    "estimator = GridSearchCV(pipe, dict(logistic__C=Cs), n_jobs=-1, scoring=score_func)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.fit(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b_est = estimator.best_estimator_\n",
    "b_params = estimator.best_params_\n",
    "b_score = estimator.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(estimator.param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_func(b_est, features, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> А теперь сравним с тем же, но без понижения размерности </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logistic = LogisticRegression(n_jobs=-1, class_weight='balanced')\n",
    "estimator_2 = GridSearchCV(logistic, dict(C=Cs), n_jobs=-1, scoring=score_func)\n",
    "estimator_2.fit(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_est2 = estimator_2.best_estimator_\n",
    "b_params2 = estimator_2.best_params_\n",
    "b_score2 = estimator_2.best_score_\n",
    "print(b_params2, b_score2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(Cs, [x[1] for x in estimator_2.grid_scores_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Cs = np.linspace(5, 10, 100)\n",
    "logistic = LogisticRegression(n_jobs=-1, class_weight='balanced')\n",
    "estimator_2 = GridSearchCV(logistic, dict(C=Cs), n_jobs=-1, scoring=score_func)\n",
    "estimator_2.fit(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_est2 = estimator_2.best_estimator_\n",
    "b_params2 = estimator_2.best_params_\n",
    "b_score2 = estimator_2.best_score_\n",
    "print(b_params2, b_score2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(Cs, [x[1] for x in estimator_2.grid_scores_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_mixed_case = CountVectorizer(lowercase=False).fit_transform(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cs = np.linspace(0.1, 10, 100)\n",
    "logistic = LogisticRegression(n_jobs=-1, class_weight='balanced')\n",
    "estimator_2 = GridSearchCV(logistic, dict(C=Cs), n_jobs=-1, scoring=score_func)\n",
    "estimator_2.fit(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_est2 = estimator_2.best_estimator_\n",
    "b_params2 = estimator_2.best_params_\n",
    "b_score2 = estimator_2.best_score_\n",
    "print(b_params2, b_score2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_func(b_est2, features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_func(LogisticRegression(), features_mixed_case, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h3><p>Применение других классификаторов вместо логистической регрессии повысить скор не помогло</p>\n",
    "<p>В среднем, линейные классификаторы дали скор ~90%</p><h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 11) Выводы:</h2>\n",
    "<h4><p> 1. Tfidf нужна большая выборка для обучения, на малой мусорные слова могут приобретать большой вес. </p>\n",
    "<p> 2. Соответственно TfidfVectorizer не всегда лучше, чем CountVectorizer </p>\n",
    "<p> 3. Иногда можно уменьшать размерность используя max_features у vectorizer'a вместо PCA, SVD, особо не теряя в качестве, но значительно выигрывая в скорости </p>\n",
    "<p> 3. Байесовским методам нужна значительно бОльшая выборка, чем в этом случае. </p>\n",
    "<p> 4. При малых размерах выборки опираться на коллокации неэффективныо</p>\n",
    "<p> 5. Используя одинаковое решение можно получить разные результаты на кросс-валидации </p>\n",
    "</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
